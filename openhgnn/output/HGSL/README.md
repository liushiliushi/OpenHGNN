# HGSL[AAAI 2021]

Paper: [Heterogeneous Graph Structure Learning for Graph Neural Networks](http://www.shichuan.org/doc/100.pdf)

Code from author:
https://github.com/Andy-Border/HGSL

### How to run

Clone the Openhgnn-DGL

```bash
python main.py -m HGSL -d acm4HGSL -t node_classification -g 0 --use_best_config
```

If you do not have gpu, set -gpu -1.
	
### Performance

Node classification

| Node classification | acm4HGSL macro-f1 | acm4HGSL micro-f1 |
| ------------------- | ----------------  | ----------------  |
| paper               | 93.48             | 93.37             |
| OpenHGNN            | 93.28             | 93.18             |

### TrainerFlow: node_classification

The model is trained in semi-supervisied node classification.

#### model

- [GraphGenerator](../../models/HGSL.py)
  - Contain MetricCalcLayer.
  - Generate graph according to two feature matrices.
- [MetricCalcLayer](../../models/HGSL.py)
  - Calculate metric.
- [GraphChannelAttLayer](../../models/HGSL.py)
  - Perform the channel attention operation on several similarity graphs. 
- [GCN](../../models/HGSL.py)
  - Contain GraphConvolution.
  - Downstream GNN.
- [GraphConvolution](../../models/HGSL.py)
  - Graph convolution layer of GCN.

### Dataset

Supported dataset: acm4HGSL

We process the [acm4GTN](../../dataset/#ACM) dataset with adding the metapath2vec embeddings from the dataset in the repository of author's code. It saved as dgl.hetrograph and can be loaded by pickle.load.

Requirements for datasets
- The graph should be an undirected heterogeneous graph.
- Every node type in graph should have its feature named 'h' and the same feature dimension.
- Every node type in graph should have its metapath2vec embedding feature named 'xxx_m2v_emb' and the same feature dimension.

### Hyper-parameter specific to the model

```python
hidden_dim = 16
num_heads = 2
gnn_emd_dim = 64
```
Best config for each dataset can be found in [best_config](../../utils/best_config.py)

### Related API in DGL

[dgl.DGLGraph.adj](https://docs.dgl.ai/generated/dgl.DGLGraph.adj.html#dgl.DGLGraph.adj)

## Note
This model under the best config has some slight differences compared with the code given by the paper authorï¼Œwhich seems having little impact on performance:
1. The regularization item in loss is on all parameters of the model, while in the author's code, it is only on the generated adjacent matrix. If you want to implement the latter, a new task is needed.
2. The normalization of input adjacent matrix is separately on different adjacent matrices of different relations, while in the author's code, it is on the entire adjacent matrix composed of all relations.

## More

#### Contirbutor

Xinlong Zhai[GAMMA LAB]

#### If you have any questions,

Submit an issue or email to [zhaijojo@bupt.edu.cn](mailto:zhaijojo@bupt.edu.cn).
